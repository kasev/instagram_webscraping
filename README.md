# Webscraping Instagram with Python


---

## Purpose

This repo contains a couple of jupyter notebooks to be used for scraping posts from instagram on the basis of a hashtag.

The scripts are configured to be executible fully online, using [mybinder](https://mybinder.org) or a similar jupyter hub server environment. To use mybinder, use the link below:

[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/kasev/webscraping_instagram/master)

---
## Authors
* Vojtěch Kaše [![](https://orcid.org/sites/default/files/images/orcid_16x16.png)]([0000-0002-6601-1605](https://www.google.com/url?q=http://orcid.org/0000-0002-6601-1605&sa=D&ust=1588773325679000)), SDAM project, vojtech.kase@gmail.com

## License
CC-BY-SA 4.0, see attached License.md

---
# How to use this repository

## Sources and prerequisites
[Describe the provenance of data used in the scripts contained and clarify how it is harvested and what other prerequisites are required to get the scripts working. In case of pure tool attribute any reused scripts to source, etc., license and specify any prerequisites or technical requirements.]

### Data
Anything else on data metadata and data used. Link to data repository or explanatory article. 

### Software
* Python 3 with packages specified in requirements.txt

### Registered account
1. sciencedata.dk
2. google (optional)
3. github (optional)


---
## Installation
---
Click on the badge below and wait - mybinder install all you need


## Instructions 

1. setup your sciencedata.dk account and choose a folder where you want to save your data
2. launch the repository on mybinder using the badge
3. for a full integration with google, create a Google API key & Google Service Account Credentials files and upload them to your sciencedata or elsewhere (from where you can read them to your python environment).
4. use mybinder terminal with preinstalled git to get your scripts back to github 






